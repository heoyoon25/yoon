import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    confusion_matrix, roc_curve, auc, ConfusionMatrixDisplay
)
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.feature_selection import SequentialFeatureSelector

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="ë¡œì§“ ëª¨í˜• ë¶„ì„ê¸° (T-test Linked)", layout="wide")

st.title("ğŸ“Š Logistic Regression Tool (T-test -> Stepwise Link)")
st.markdown("---")

# ==========================================
# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
# ==========================================
if 'df' not in st.session_state:
    st.session_state['df'] = None
if 'recommended_features' not in st.session_state:
    st.session_state['recommended_features'] = [] # Stepwise ê²°ê³¼ ì €ì¥ìš©
if 'significant_features' not in st.session_state:
    st.session_state['significant_features'] = [] # T-test ê²°ê³¼ ì €ì¥ìš© (NEW)

# ==========================================
# 1. ë°ì´í„° ì—…ë¡œë“œ
# ==========================================
st.header("1. ë°ì´í„° ì—…ë¡œë“œ")
uploaded_file = st.file_uploader("CSV íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["csv"])

if uploaded_file is not None:
    st.session_state['df'] = pd.read_csv(uploaded_file)
    st.success("ë°ì´í„° ì—…ë¡œë“œ ì„±ê³µ!")
    
    # ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°
    st.dataframe(st.session_state['df'].head())
    
    if 'not.fully.paid' not in st.session_state['df'].columns:
        st.error("âš ï¸ ê²½ê³ : ì—…ë¡œë“œëœ ë°ì´í„°ì— 'not.fully.paid' ë³€ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤.")

# ë°ì´í„°ê°€ ìˆì„ ë•Œë§Œ ì‹¤í–‰
if st.session_state['df'] is not None and 'not.fully.paid' in st.session_state['df'].columns:
    df = st.session_state['df']
    target_col = 'not.fully.paid'

    st.markdown("---")
    # ==========================================
    # 2. ë°ì´í„° íƒìƒ‰ (T-test ë¡œì§ ìˆ˜ì •ë¨)
    # ==========================================
    st.header("2. ë°ì´í„° íƒìƒ‰ ë° ì‹œê°í™” (EDA)")

    st.subheader(f"ê°€ì„¤ ê²€ì • (Target: {target_col} ê¸°ì¤€)")
    st.caption(f"'{target_col}'(0/1)ì— ë”°ë¼ í‰ê·  ì°¨ì´ê°€ ìœ ì˜ë¯¸í•œ(p<=0.05) ë³€ìˆ˜ë§Œ ì¶”ì¶œí•˜ì—¬ **Stepwise í›„ë³´ë¡œ ë“±ë¡í•©ë‹ˆë‹¤.**")

    if st.button("ìœ ì˜í•œ ë³€ìˆ˜ ì°¾ê¸° (T-test)"):
        if df[target_col].nunique() != 2:
            st.error(f"ì˜¤ë¥˜: '{target_col}' ë³€ìˆ˜ì˜ ê°’ì´ 2ê°œ(0ê³¼ 1)ê°€ ì•„ë‹™ë‹ˆë‹¤.")
        else:
            numeric_cols = df.select_dtypes(include=np.number).columns.tolist()
            if target_col in numeric_cols:
                numeric_cols.remove(target_col)
            
            significant_vars = []
            sig_names_temp = [] # ë³€ìˆ˜ëª…ë§Œ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
            groups = df[target_col].unique()
            
            for col in numeric_cols:
                try:
                    group_a = df[df[target_col] == groups[0]][col]
                    group_b = df[df[target_col] == groups[1]][col]
                    
                    t_stat, p_val = stats.ttest_ind(group_a, group_b, equal_var=False, nan_policy='omit')
                    
                    if p_val <= 0.05:
                        significant_vars.append({
                            "ë³€ìˆ˜ëª…": col,
                            "T-statistic": round(t_stat, 4),
                            "P-value": round(p_val, 5)
                        })
                        sig_names_temp.append(col)
                except:
                    pass

            if significant_vars:
                # [í•µì‹¬] ë°œê²¬ëœ ìœ ì˜ë¯¸í•œ ë³€ìˆ˜ë“¤ì„ ì„¸ì…˜ì— ì €ì¥
                st.session_state['significant_features'] = sig_names_temp
                
                st.success(f"ìœ ì˜ë¯¸í•œ ë³€ìˆ˜ {len(significant_vars)}ê°œ ë°œê²¬ ë° ì €ì¥ ì™„ë£Œ!")
                st.dataframe(pd.DataFrame(significant_vars))
                st.info("ğŸ‘‡ ì´ ë³€ìˆ˜ë“¤ì´ 4ë²ˆ Stepwise ì„ íƒ ë‹¨ê³„ì˜ 'í›„ë³´ ë³€ìˆ˜'ë¡œ ìë™ ì„¤ì •ë©ë‹ˆë‹¤.")
            else:
                st.warning("P-value <= 0.05ì¸ ë³€ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤.")
                st.session_state['significant_features'] = []

    st.markdown("---")
    # 2-2. ì‹œê°í™” (ìƒëµ ì—†ì´ ìœ ì§€)
    st.subheader("ê·¸ë˜í”„ ì‹œê°í™”")
    v_col1, v_col2, v_col3 = st.columns(3)
    with v_col1: x_axis = st.selectbox("Xì¶• ì„ íƒ", df.columns)
    with v_col2: y_axis = st.selectbox("Yì¶• ì„ íƒ (ì„ íƒ)", [None] + list(df.columns))
    with v_col3: plot_type = st.selectbox("ê·¸ë˜í”„ ìœ í˜•", ["Histogram", "Box Plot", "Scatter Plot", "Bar Chart", "Line Chart"])

    if st.button("ê·¸ë˜í”„ ê·¸ë¦¬ê¸°"):
        fig, ax = plt.subplots(figsize=(10, 5))
        try:
            if plot_type == "Histogram": sns.histplot(data=df, x=x_axis, hue=target_col, kde=True, ax=ax)
            elif plot_type == "Box Plot": sns.boxplot(data=df, x=x_axis, y=y_axis, ax=ax)
            elif plot_type == "Scatter Plot":
                if y_axis: sns.scatterplot(data=df, x=x_axis, y=y_axis, hue=target_col, ax=ax)
                else: st.warning("Yì¶•ì„ ì„ íƒí•˜ì„¸ìš”.")
            elif plot_type == "Bar Chart":
                if y_axis: sns.barplot(data=df, x=x_axis, y=y_axis, ax=ax)
                else: sns.countplot(data=df, x=x_axis, ax=ax)
            elif plot_type == "Line Chart":
                if y_axis: sns.lineplot(data=df, x=x_axis, y=y_axis, ax=ax)
                else: st.warning("Yì¶•ì„ ì„ íƒí•˜ì„¸ìš”.")
            st.pyplot(fig)
        except Exception as e: st.error(f"ì˜¤ë¥˜: {e}")

    st.markdown("---")
    # ==========================================
    # 3. ë°ì´í„° ì „ì²˜ë¦¬
    # ==========================================
    st.header("3. ë°ì´í„° ì „ì²˜ë¦¬")
    
    c1, c2, c3 = st.columns(3)
    handle_na = c1.checkbox("ê²°ì¸¡ì¹˜ ì œê±°", value=True)
    do_scaling = c2.checkbox("ìŠ¤ì¼€ì¼ë§ (StandardScaler)")
    do_encoding = c3.checkbox("ì›-í•« ì¸ì½”ë”©")

    if st.button("ì „ì²˜ë¦¬ ì ìš©"):
        df_proc = df.copy()
        if handle_na: df_proc = df_proc.dropna()
        
        if do_encoding:
            cat_cols = df_proc.select_dtypes(include=['object', 'category']).columns
            if len(cat_cols) > 0:
                df_proc = pd.get_dummies(df_proc, columns=cat_cols, drop_first=True)
        
        if do_scaling:
            num_cols = df_proc.select_dtypes(include=np.number).columns.tolist()
            if target_col in num_cols: num_cols.remove(target_col)
            scaler = StandardScaler()
            df_proc[num_cols] = scaler.fit_transform(df_proc[num_cols])

        st.session_state['df_processed'] = df_proc
        st.session_state['recommended_features'] = [] 
        st.success("ì „ì²˜ë¦¬ ì™„ë£Œ")
        st.dataframe(df_proc.head())

    current_df = st.session_state.get('df_processed', df)

    st.markdown("---")
    # ==========================================
    # 4. íŠ¹ì„± ì„ íƒ (Stepwise) - T-test ì—°ë™ ìˆ˜ì •ë¨
    # ==========================================
    st.header("4. íŠ¹ì„± ì„ íƒ (Stepwise Selection)")
    st.info(f"ğŸ“ ì¢…ì† ë³€ìˆ˜(Y): **'{target_col}'**")

    # ë…ë¦½ ë³€ìˆ˜ í›„ë³´êµ° (ì „ì²´ ì»¬ëŸ¼ ì¤‘ íƒ€ê²Ÿ ì œì™¸)
    feature_candidates = [c for c in current_df.columns if c != target_col]

    # [í•µì‹¬] Default ê°’ ê²°ì • ë¡œì§
    # 1ìˆœìœ„: T-testì—ì„œ ìœ ì˜í•˜ë‹¤ê³  íŒëª…ëœ ë³€ìˆ˜ë“¤ (st.session_state['significant_features'])
    # 2ìˆœìœ„: T-testë¥¼ ì•ˆ ëŒë ¸ë‹¤ë©´ ì „ì²´ ë³€ìˆ˜
    
    default_candidates = []
    
    if st.session_state['significant_features']:
        # T-test ë³€ìˆ˜ ì¤‘ í˜„ì¬ ë°ì´í„°í”„ë ˆì„(ì „ì²˜ë¦¬ í›„)ì— ì‹¤ì œë¡œ ì¡´ì¬í•˜ëŠ” ê²ƒë§Œ í•„í„°ë§
        default_candidates = [f for f in st.session_state['significant_features'] if f in feature_candidates]
        st.success(f"âœ… T-test ê²€ì • ê²°ê³¼, ìœ ì˜ë¯¸í•œ ë³€ìˆ˜ {len(default_candidates)}ê°œê°€ ê¸°ë³¸ ì„ íƒë˜ì—ˆìŠµë‹ˆë‹¤.")
    else:
        # T-test ì•ˆ ëŒë ¸ìœ¼ë©´ ì „ì²´ ì„ íƒ
        default_candidates = feature_candidates

    selected_features_pool = st.multiselect(
        "Stepwise í›„ë³´ ë³€ìˆ˜ ì„ íƒ", 
        options=feature_candidates, 
        default=default_candidates
    )

    if st.button("ì „ì§„ ì„ íƒë²•(Stepwise) ì‹¤í–‰"):
        if not selected_features_pool:
            st.warning("ë³€ìˆ˜ë¥¼ ì„ íƒí•˜ì„¸ìš”.")
        else:
            X_temp = current_df[selected_features_pool]
            y_temp = current_df[target_col]
            
            le = LabelEncoder()
            y_encoded = le.fit_transform(y_temp)

            try:
                model_sel = LogisticRegression(solver='liblinear') 
                sfs = SequentialFeatureSelector(model_sel, direction='forward', n_features_to_select='auto')
                
                with st.spinner("ìµœì  ë³€ìˆ˜ íƒìƒ‰ ì¤‘..."):
                    sfs.fit(X_temp, y_encoded)
                
                selected_mask = sfs.get_support()
                recommended = np.array(selected_features_pool)[selected_mask]
                
                # ê²°ê³¼ ì €ì¥
                st.session_state['recommended_features'] = list(recommended)
                st.success(f"ì¶”ì²œ ë³€ìˆ˜ ({len(recommended)}ê°œ): {', '.join(recommended)}")
                st.info("ğŸ‘‡ ì•„ë˜ 'ìµœì¢… ë…ë¦½ ë³€ìˆ˜ ì„ íƒ' ë€ì— ìë™ìœ¼ë¡œ ë°˜ì˜ë˜ì—ˆìŠµë‹ˆë‹¤.")
                
            except Exception as e:
                st.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")


    st.markdown("---")
    # ==========================================
    # 5 & 6. ìµœì¢… ëª¨ë¸ë§ (SMOTE + í™•ë¥  ë¶„í¬ í™•ì¸)
    # ==========================================
    st.header("5 & 6. ìµœì¢… ë³€ìˆ˜ ì„ íƒ ë° ëª¨ë¸ í‰ê°€")

    # imblearn ë¼ì´ë¸ŒëŸ¬ë¦¬ ì²´í¬
    try:
        from imblearn.over_sampling import SMOTE
    except Exception as e:
        st.error(f"âš ï¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì˜¤ë¥˜ ë°œìƒ: {e}")
        st.stop()

    c_final1, c_final2 = st.columns(2)

    # Stepwise ê²°ê³¼ê°€ ìˆìœ¼ë©´ Defaultë¡œ ì‚¬ìš©
    final_default = [f for f in st.session_state['recommended_features'] if f in feature_candidates]
    
    final_features = c_final1.multiselect(
        "ìµœì¢… ë…ë¦½ ë³€ìˆ˜ ì„ íƒ", 
        options=feature_candidates,
        default=final_default
    )
    
    test_size = c_final2.slider("Test Size", 0.1, 0.5, 0.2)

    st.subheader("âš™ï¸ ë¶ˆê· í˜• ë°ì´í„° ì²˜ë¦¬ ì˜µì…˜")
    h1, h2, h3 = st.columns(3)
    
    # 1. SMOTE ì‚¬ìš© ì—¬ë¶€
    use_smote = h1.checkbox("SMOTE ì˜¤ë²„ìƒ˜í”Œë§ ì ìš©", value=True, 
                            help="ê°€ì¥ ê°•ë ¥í•œ ë°©ë²•ì…ë‹ˆë‹¤. í•™ìŠµ ë°ì´í„°ì˜ ì†Œìˆ˜ í´ë˜ìŠ¤(1)ë¥¼ ê°€ìƒìœ¼ë¡œ ìƒì„±í•˜ì—¬ ë¹„ìœ¨ì„ ë§ì¶¥ë‹ˆë‹¤.")
    
    # 2. ì„ê³„ê°’ ì„¤ì •
    threshold = h2.slider("ë¶„ë¥˜ ì„ê³„ê°’ (Threshold)", 0.0, 1.0, 0.5, 0.01,
                          help="í™•ë¥ ì´ ì´ ê°’ë³´ë‹¤ í¬ë©´ 1(ë¶€ë„)ë¡œ ì˜ˆì¸¡í•©ë‹ˆë‹¤.")

    if st.button("ëª¨ë¸ í•™ìŠµ ë° í‰ê°€"):
        if not final_features:
            st.error("ë³€ìˆ˜ë¥¼ ì„ íƒí•˜ì„¸ìš”.")
        else:
            X = current_df[final_features]
            y = current_df[target_col]

            # ì¸ì½”ë”©
            le_final = LabelEncoder()
            y_encoded_final = le_final.fit_transform(y)

            # 1. Train/Test Split
            X_train, X_test, y_train, y_test = train_test_split(X, y_encoded_final, test_size=test_size, random_state=42)

            # 2. SMOTE ì ìš© (í•™ìŠµ ë°ì´í„°ì—ë§Œ!)
            if use_smote:
                smote = SMOTE(random_state=42)
                X_train_res, y_train_res = smote.fit_resample(X_train, y_train)
                st.info(f"âš¡ SMOTE ì ìš© ì™„ë£Œ: í•™ìŠµ ë°ì´í„°ê°€ {len(y_train)}ê°œì—ì„œ {len(y_train_res)}ê°œë¡œ ì¦ê°€í–ˆìŠµë‹ˆë‹¤. (ë¹„ìœ¨ 1:1)")
            else:
                X_train_res, y_train_res = X_train, y_train

            # 3. ëª¨ë¸ í•™ìŠµ
            model = LogisticRegression(max_iter=5000) # SMOTE ì“°ë©´ class_weightëŠ” êµ³ì´ ì•ˆì¨ë„ ë¨
            model.fit(X_train_res, y_train_res)
            
            # 4. ì˜ˆì¸¡ (í™•ë¥ ê°’ ì¶”ì¶œ)
            y_proba = model.predict_proba(X_test)[:, 1]
            
            # 5. ì‚¬ìš©ì ì§€ì • ì„ê³„ê°’ ì ìš©
            y_pred = (y_proba >= threshold).astype(int)

            # --- ê²°ê³¼ ì¶œë ¥ ---
            st.subheader("ëª¨ë¸ ì„±ëŠ¥")
            
            # ì‹¤ì œ Test ë°ì´í„°ì— 1ì´ ëª‡ ê°œì¸ì§€ í™•ì¸ (ë””ë²„ê¹…ìš©)
            unique, counts = np.unique(y_test, return_counts=True)
            test_ratio = dict(zip(unique, counts))
            st.caption(f"ğŸ“Œ ê²€ì¦ ë°ì´í„°(Test Set) ì‹¤ì œ ë¶„í¬: {test_ratio} (ì—¬ê¸°ì„œ 1ì´ ë„ˆë¬´ ì ìœ¼ë©´ ìˆ˜ì¹˜ê°€ ì˜ ì•ˆ ë‚˜ì˜¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤)")

            m1, m2, m3, m4 = st.columns(4)
            m1.metric("Accuracy", f"{accuracy_score(y_test, y_pred):.4f}")
            m2.metric("Precision", f"{precision_score(y_test, y_pred, zero_division=0):.4f}")
            m3.metric("Recall", f"{recall_score(y_test, y_pred, zero_division=0):.4f}")
            m4.metric("F1 Score", f"{f1_score(y_test, y_pred, zero_division=0):.4f}")

            # --- ì‹œê°í™” ---
            st.subheader("ì‹œê°í™” ë° ì§„ë‹¨")
            
            # [NEW] í™•ë¥  ë¶„í¬ íˆìŠ¤í† ê·¸ë¨ (ì´ê²Œ ì¤‘ìš”í•©ë‹ˆë‹¤!)
            st.write("#### 1. ì˜ˆì¸¡ í™•ë¥  ë¶„í¬ (Probability Histogram)")
            st.caption("ëª¨ë¸ì´ ì˜ˆì¸¡í•œ í™•ë¥ ê°’ë“¤ì´ ì–´ë””ì— ëª°ë ¤ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”. ë¹¨ê°„ì„ ì€ í˜„ì¬ ì„¤ì •í•œ ì„ê³„ê°’ì…ë‹ˆë‹¤.")
            
            fig_hist, ax_hist = plt.subplots(figsize=(10, 3))
            sns.histplot(y_proba, bins=50, kde=True, ax=ax_hist, color='skyblue')
            ax_hist.axvline(threshold, color='red', linestyle='--', label=f'Threshold: {threshold}')
            ax_hist.set_xlabel("Predicted Probability (Score)")
            ax_hist.legend()
            st.pyplot(fig_hist)
            
            gc1, gc2 = st.columns(2)
            with gc1:
                st.write("#### 2. Confusion Matrix")
                cm = confusion_matrix(y_test, y_pred)
                fig_cm, ax_cm = plt.subplots()
                sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax_cm, annot_kws={"size": 14})
                ax_cm.set_xlabel('Predicted Label')
                ax_cm.set_ylabel('True Label')
                st.pyplot(fig_cm)
            
            with gc2:
                st.write("#### 3. ROC Curve")
                fpr, tpr, _ = roc_curve(y_test, y_proba)
                roc_auc = auc(fpr, tpr)
                fig_roc, ax_roc = plt.subplots()
                ax_roc.plot(fpr, tpr, color='orange', label=f'AUC = {roc_auc:.2f}')
                ax_roc.plot([0,1],[0,1], 'k--')
                ax_roc.legend()
                st.pyplot(fig_roc)
